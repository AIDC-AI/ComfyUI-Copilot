[
    {
        "name": "添加LoRA",
        "description": "在现有工作流中添加LoRA节点",
        "content": "在现有工作流中添加LoRA节点，确保与现有模型和提示词节点正确连接\n    在checkpoint节点后添加LoRA节点。\n    {\n      \"1\": {\n         \"inputs\": {\n            \"lora_name\": \"DOG.safetensors\",\n            \"strength_model\": 1,\n            \"strength_clip\": 1,\n            \"model\": [\n            \"2\",\n            0\n            ],\n            \"clip\": [\n            \"2\",\n            1\n            ]\n         },\n         \"class_type\": \"LoraLoader\",\n         \"_meta\": {\n            \"title\": \"Load LoRA\"\n         }\n      }"
    },
    {
        "name": "后处理增强",
        "description": "后处理增强，例如在Preview Image或Save Image节点后添加高清放大功能（如Real-ESRGAN、ESRGAN等）; 或者添加图像缩放节点",
        "content": "- 在Preview Image或Save Image节点后添加高清放大功能（如Real-ESRGAN、ESRGAN等）\n       - 添加图像缩放节点\n       {\n  \"1\": {\n    \"inputs\": {\n      \"width\": 512,\n      \"height\": 512,\n      \"interpolation\": \"nearest\",\n      \"method\": \"stretch\",\n      \"condition\": \"always\",\n      \"multiple_of\": 0\n    },\n    \"class_type\": \"ImageResize+\",\n    \"_meta\": {\n      \"title\": \"🔧 Image Resize\"\n    }\n  }\n}\n       - 添加图像尺寸调整节点\n       {\n  \"2\": {\n    \"inputs\": {\n      \"aspect_ratio\": \"original\",\n      \"proportional_width\": 2,\n      \"proportional_height\": 1,\n      \"fit\": \"letterbox\",\n      \"method\": \"lanczos\",\n      \"round_to_multiple\": \"8\",\n      \"scale_to_longest_side\": false,\n      \"longest_side\": 1024\n    },\n    \"class_type\": \"LayerUtility: ImageScaleByAspectRatio\",\n    \"_meta\": {\n      \"title\": \"LayerUtility: ImageScaleByAspectRatio\"\n    }\n  }\n}\n   -添加图像放大节点\n  \"11\": {\n    \"inputs\": {\n      \"width\": 512,\n      \"height\": 512,\n      \"upscale_method\": \"nearest-exact\",\n      \"keep_proportion\": false,\n      \"divisible_by\": 2,\n      \"crop\": \"disabled\",\n      \"image\": [\n        \"12\",\n        0\n      ]\n    },\n    \"class_type\": \"ImageResizeKJ\",\n    \"_meta\": {\n      \"title\": \"Resize Image\"\n    }\n  },\n   -添加VAEdecode节点\n  \"12\": {\n    \"inputs\": {},\n    \"class_type\": \"VAEDecode\",\n    \"_meta\": {\n      \"title\": \"VAE Decode\"\n    }\n  }\n}"
    },
    {
        "name": "提示词优化",
        "description": "修改现有提示词节点的内容(提示词应该在(CLIP Text Encode Prompt或Text _O节点内编辑); 添加单独的提示词输入节点",
        "content": "{\n  \"12\": {\n    \"inputs\": {\n      \"text\": [\n        \"13\",\n        0\n      ]\n    },\n    \"class_type\": \"CLIPTextEncode\",\n    \"_meta\": {\n      \"title\": \"CLIP Text Encode (Prompt)\"\n    }\n  },\n  \"13\": {\n    \"inputs\": {\n      \"delimiter\": \", \",\n      \"clean_whitespace\": \"true\",\n      \"text_a\": [\n        \"15\",\n        0\n      ],\n      \"text_b\": [\n        \"16\",\n        0\n      ]\n    },\n    \"class_type\": \"Text Concatenate\",\n    \"_meta\": {\n      \"title\": \"Text Concatenate\"\n    }\n  },\n  \"15\": {\n    \"inputs\": {\n      \"text\": \"\"\n    },\n    \"class_type\": \"Text _O\",\n    \"_meta\": {\n      \"title\": \"Text _O\"\n    }\n  },\n  \"16\": {\n    \"inputs\": {\n      \"text\": \"\"\n    },\n    \"class_type\": \"Text _O\",\n    \"_meta\": {\n      \"title\": \"Text _O\"\n    }\n  }\n}"
    },
    {
        "name": "图像反推",
        "description": "理解图片信息并用文字表达出来",
        "content": "添加图像反推节点（如CLIP Interrogator）\n{\n  \"11\": {\n    \"inputs\": {\n      \"prompt_mode\": \"fast\",\n      \"image_analysis\": \"off\"\n    },\n    \"class_type\": \"ClipInterrogator\",\n    \"_meta\": {\n      \"title\": \"Clip Interrogator ♾️Mixlab\"\n    }\n  }\n}\n       - 添加更复杂或者更好用的图像反推节点(加载图片使用florence2进行反推)\n       {\n  \"6\": {\n    \"inputs\": {\n      \"image\": \"06.JPG\"\n    },\n    \"class_type\": \"LoadImage\",\n    \"_meta\": {\n      \"title\": \"$image.image!:The image to analyze, must be a url\"\n    }\n  },\n  \"10\": {\n    \"inputs\": {\n      \"model\": \"microsoft/Florence-2-large\",\n      \"precision\": \"fp16\",\n      \"attention\": \"sdpa\"\n    },\n    \"class_type\": \"DownloadAndLoadFlorence2Model\",\n    \"_meta\": {\n      \"title\": \"DownloadAndLoadFlorence2Model\"\n    }\n  },\n  \"11\": {\n    \"inputs\": {\n      \"text_input\": \"\",\n      \"task\": \"more_detailed_caption\",\n      \"fill_mask\": true,\n      \"keep_model_loaded\": false,\n      \"max_new_tokens\": 1024,\n      \"num_beams\": 3,\n      \"do_sample\": true,\n      \"output_mask_select\": \"\",\n      \"seed\": 1098631327477633,\n      \"image\": [\n        \"6\",\n        0\n      ],\n      \"florence2_model\": [\n        \"10\",\n        0\n      ]\n    },\n    \"class_type\": \"Florence2Run\",\n    \"_meta\": {\n      \"title\": \"Florence2Run\"\n    }\n  },\n  \"18\": {\n    \"inputs\": {\n      \"anything\": [\n        \"11\",\n        2\n      ]\n    },\n    \"class_type\": \"easy showAnything\",\n    \"_meta\": {\n      \"title\": \"Show Any\"\n    }\n  },\n  \"20\": {\n    \"inputs\": {\n      \"value\": \"Generate high-quality text descriptions from images using local Florence model.\\n    \\n    Main use cases:\\n    1. **Reverse image prompt generation**:\\n       - When users upload an image and want to get prompts for AI art generation\\n       - Analyzes visual elements, style, composition, etc. to generate prompts for Stable Diffusion, DALL-E, and other models\\n       - In this case, return the tool's raw output directly to users without any modification or summary\\n       - Users can directly use these prompts for image generation\\n    2. **Image content understanding**:\\n       - When users ask about specific content, objects, scenes, people, etc. in the image\\n       - Need to understand the semantic content of the image and answer users' specific questions\\n       - In this case, combine tool output with conversation context to give users contextually appropriate natural responses\\n       - Don't return raw output directly, but provide targeted replies based on understanding results\"\n    },\n    \"class_type\": \"PrimitiveStringMultiline\",\n    \"_meta\": {\n      \"title\": \"MCP\"\n    }\n  }\n}"
    },
    {
        "name": "添加ControlNet",
        "description": "在使用风格迁移保持主体结构不变、保持主体形状、重新绘制背景、控制人物角色姿态、保持场景的深度和空间结构、基于线稿或者草图生成图像等场景下，可以用添加ControlNet节点来实现",
        "content": "**ControlNet集成**：(preprocessor可选canny、depth等参数,模型样式选择，Controlnet开始、结束权重)\n       {\n  \"22\": {\n    \"inputs\": {\n      \"strength\": 1,\n      \"start_percent\": 0,\n      \"end_percent\": 1,\n      \"control_net\": [\n        \"23\",\n        0\n      ],\n      \"image\": [\n        \"24\",\n        0\n      ]\n    },\n    \"class_type\": \"ControlNetApplyAdvanced\",\n    \"_meta\": {\n      \"title\": \"Apply ControlNet\"\n    }\n  },\n  \"23\": {\n    \"inputs\": {\n      \"control_net_name\": \"ControlNet-Standard-Lineart-for-SDXL.safetensors\"\n    },\n    \"class_type\": \"ControlNetLoader\",\n    \"_meta\": {\n      \"title\": \"Load ControlNet Model\"\n    }\n  },\n  \"24\": {\n    \"inputs\": {\n      \"preprocessor\": \"none\",\n      \"resolution\": 512\n    },\n    \"class_type\": \"AIO_Preprocessor\",\n    \"_meta\": {\n      \"title\": \"AIO Aux Preprocessor\"\n    }\n  }\n}"
    },
    {
        "name": "扩图",
        "description": "给我一个扩图链路(包括图像加载和图像输出)",
        "content": "{\n  \"1\": {\n    \"inputs\": {\n      \"image\": \"01.JPG\"\n    },\n    \"class_type\": \"LoadImage\",\n    \"_meta\": {\n      \"title\": \"$image.image!:The image to analyze, must be a url\"\n    }\n  },\n  \"2\": {\n    \"inputs\": {\n      \"model\": \"runwayml/stable-diffusion-xl-base-1.0\",\n      \"precision\": \"fp16\",\n      \"attention\": \"sdpa\"\n    },\n    \"class_type\": \"DownloadAndLoadModel\",\n    \"_meta\": {\n      \"title\": \"DownloadAndLoadModel\"\n    }\n  },\n  \"3\": {\n    \"inputs\": {\n      \"prompt\": \"A beautiful girl with long hair and a white dress\",\n      \"image\": [\n        \"1\",\n        0\n      ],\n      \"model\": [\n        \"2\",\n        0\n      ]\n    },\n    \"class_type\": \"StableDiffusionXLRun\",\n    \"_meta\": {\n      \"title\": \"StableDiffusionXLRun\"\n    }\n  },\n  \"4\": {\n    \"inputs\": {\n      \"image\": [\n        \"3\",\n        0\n      ]\n    },\n    \"class_type\": \"easy showImage\",\n    \"_meta\": {\n      \"title\": \"Show Image\"\n    }\n  }\n}"
    },
    {
        "name": "智能抠图",
        "description": "添加背景移除节点（如SAM、U²-Net等）",
        "content": "- 添加背景移除或抠图节点\n       {\n  \"7\": {\n    \"inputs\": {\n      \"rem_mode\": \"RMBG-1.4\",\n      \"image_output\": \"Preview\",\n      \"save_prefix\": \"ComfyUI\",\n      \"torchscript_jit\": false,\n      \"add_background\": \"none\",\n      \"refine_foreground\": false\n    },\n    \"class_type\": \"easy imageRemBg\",\n    \"_meta\": {\n      \"title\": \"Image Remove Bg\"\n    }\n  }\n}\n       - 添加SAM抠图节点\n       {\n  \"8\": {\n    \"inputs\": {\n      \"prompt\": \"\",\n      \"threshold\": 0.3,\n      \"sam_model\": [\n        \"9\",\n        0\n      ],\n      \"grounding_dino_model\": [\n        \"10\",\n        0\n      ]\n    },\n    \"class_type\": \"GroundingDinoSAMSegment (segment anything)\",\n    \"_meta\": {\n      \"title\": \"GroundingDinoSAMSegment (segment anything)\"\n    }\n  },\n  \"9\": {\n    \"inputs\": {\n      \"model_name\": \"sam_vit_h (2.56GB)\"\n    },\n    \"class_type\": \"SAMModelLoader (segment anything)\",\n    \"_meta\": {\n      \"title\": \"SAMModelLoader (segment anything)\"\n    }\n  },\n  \"10\": {\n    \"inputs\": {\n      \"model_name\": \"GroundingDINO_SwinT_OGC (694MB)\"\n    },\n    \"class_type\": \"GroundingDinoModelLoader (segment anything)\",\n    \"_meta\": {\n      \"title\": \"GroundingDinoModelLoader (segment anything)\"\n    }\n  }\n}"
    },
    {
        "name": "kontext图像编辑",
        "description": "添加kontext系列节点(这个系列是文生图和图生图场景应用的模型和节点,适合用针对图像的融合，二次编辑,包括但不限于去水印、擦除物体、多元素融合、图片元素提取等)",
        "content": "{\n  \"6\": {\n    \"inputs\": {\n      \"text\": \"\",\n      \"clip\": [\n        \"38\",\n        0\n      ]\n    },\n    \"class_type\": \"CLIPTextEncode\",\n    \"_meta\": {\n      \"title\": \"CLIP Text Encode (Prompt)\"\n    }\n  },\n  \"8\": {\n    \"inputs\": {\n      \"samples\": [\n        \"31\",\n        0\n      ],\n      \"vae\": [\n        \"39\",\n        0\n      ]\n    },\n    \"class_type\": \"VAEDecode\",\n    \"_meta\": {\n      \"title\": \"VAE Decode\"\n    }\n  },\n  \"31\": {\n    \"inputs\": {\n      \"seed\": 584043043142251,\n      \"steps\": 30,\n      \"cfg\": 1.5,\n      \"sampler_name\": \"euler\",\n      \"scheduler\": \"simple\",\n      \"denoise\": 1,\n      \"model\": [\n        \"37\",\n        0\n      ],\n      \"positive\": [\n        \"35\",\n        0\n      ],\n      \"negative\": [\n        \"135\",\n        0\n      ],\n      \"latent_image\": [\n        \"124\",\n        0\n      ]\n    },\n    \"class_type\": \"KSampler\",\n    \"_meta\": {\n      \"title\": \"KSampler\"\n    }\n  },\n  \"35\": {\n    \"inputs\": {\n      \"guidance\": 2.5,\n      \"conditioning\": [\n        \"177\",\n        0\n      ]\n    },\n    \"class_type\": \"FluxGuidance\",\n    \"_meta\": {\n      \"title\": \"FluxGuidance\"\n    }\n  },\n  \"37\": {\n    \"inputs\": {\n      \"unet_name\": \"flux1-dev-kontext_fp8_scaled.safetensors\",\n      \"weight_dtype\": \"fp8_e4m3fn\"\n    },\n    \"class_type\": \"UNETLoader\",\n    \"_meta\": {\n      \"title\": \"Load Diffusion Model\"\n    }\n  },\n  \"38\": {\n    \"inputs\": {\n      \"clip_name1\": \"clip_l.safetensors\",\n      \"clip_name2\": \"t5xxl_fp16.safetensors\",\n      \"type\": \"flux\",\n      \"device\": \"default\"\n    },\n    \"class_type\": \"DualCLIPLoader\",\n    \"_meta\": {\n      \"title\": \"DualCLIPLoader\"\n    }\n  },\n  \"39\": {\n    \"inputs\": {\n      \"vae_name\": \"ae.safetensors\"\n    },\n    \"class_type\": \"VAELoader\",\n    \"_meta\": {\n      \"title\": \"Load VAE\"\n    }\n  },\n  \"42\": {\n    \"inputs\": {\n      \"image\": [\n        \"194\",\n        0\n      ]\n    },\n    \"class_type\": \"FluxKontextImageScale\",\n    \"_meta\": {\n      \"title\": \"FluxKontextImageScale\"\n    }\n  },\n  \"124\": {\n    \"inputs\": {\n      \"pixels\": [\n        \"42\",\n        0\n      ],\n      \"vae\": [\n        \"39\",\n        0\n      ]\n    },\n    \"class_type\": \"VAEEncode\",\n    \"_meta\": {\n      \"title\": \"VAE Encode\"\n    }\n  },\n  \"135\": {\n    \"inputs\": {\n      \"conditioning\": [\n        \"6\",\n        0\n      ]\n    },\n    \"class_type\": \"ConditioningZeroOut\",\n    \"_meta\": {\n      \"title\": \"ConditioningZeroOut\"\n    }\n  },\n  \"177\": {\n    \"inputs\": {\n      \"conditioning\": [\n        \"6\",\n        0\n      ],\n      \"latent\": [\n        \"124\",\n        0\n      ]\n    },\n    \"class_type\": \"ReferenceLatent\",\n    \"_meta\": {\n      \"title\": \"ReferenceLatent\"\n    }\n  },\n  \"193\": {\n    \"inputs\": {\n      \"filename_prefix\": \"ComfyUI\",\n      \"images\": [\n        \"8\",\n        0\n      ]\n    },\n    \"class_type\": \"SaveImage\",\n    \"_meta\": {\n      \"title\": \"Save Image\"\n    }\n  },\n  \"194\": {\n    \"inputs\": {\n      \"image\": \"021175655C8A2A86C831C96855F3EF23.png\"\n    },\n    \"class_type\": \"LoadImage\",\n    \"_meta\": {\n      \"title\": \"Load Image\"\n    }\n  }\n}"
    },
    {
        "name": "qwen image图像生成",
        "description": "基于Qwen-Image多模态大模型的文生图解决方案，支持中英文提示词，擅长生成包含复杂文本的图像内容。适用于海报设计、广告创意等需要稳定生成文字内容的场景",
        "content": "添加qwen image模型,使用qwen image 文生图，创作一张海报，适合生成稳定的文字(当用户提到需要使用qwen image系列时给它提供如下的节点和模型选择：load Difussion Model节点对应qwen_image名字的模型，Load CLIP对应的clip_name:qwen_2.5_vl,type：qwen_image,Load VAE节点对应的模型为:qwen_image_vae.safetensors)"
    }
]